A good start would be tokenizing dialectics. This is mostly a linguistic problem, but should be fun. Give user opportunity to alter ambigious tokens, or report mis-tokenization. Choice of default token is an interrestign machine learning problem. Tokens can come in several packages, for instance english (dictionary) and mathematics.
